{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The University of Melbourne, School of Computing and Information Systems\n",
    "\n",
    "# COMP30027 Machine Learning, 2024 Semester 1\n",
    "\n",
    "## Assignment 1: Wine quality classification with K-NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s):** `1269602`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-NN classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k, debug=False):\n",
    "        self.k = k\n",
    "        self.debug = debug\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for _, row in X_test.iterrows():\n",
    "            # For each instance in test, compute euclidean distance to each instance in training \n",
    "            distances = [self.euclidean_distance(row.values, x_train) for _, x_train in self.X_train.iterrows()]\n",
    "            # Find nearest neighbours and take their labels \n",
    "            nearest_neighbors = np.argsort(distances)[:self.k]\n",
    "            nearest_labels = [self.y_train[neighbor] for neighbor in nearest_neighbors]\n",
    "\n",
    "            if self.debug:\n",
    "                print(\"Instance\", _)\n",
    "                print(\"Distance Array\", distances)\n",
    "                print(f'Indexes of {self.k} nearest neighbours', nearest_neighbors)\n",
    "                print('With labels:', nearest_labels)\n",
    "\n",
    "            # Majority Vote (when K > 1)\n",
    "            label_counts = Counter(nearest_labels)\n",
    "            most_common = label_counts.most_common()\n",
    "\n",
    "            # Choose winning label\n",
    "            if len(most_common) == 1 or most_common[0][1] > most_common[1][1]:\n",
    "                predictions.append(most_common[0][0])\n",
    "            else:\n",
    "                # Tie-break by taking label of 1-NN \n",
    "                predictions.append(nearest_labels[0])\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training and testing dataset into dataframes\n",
    "train_df = pd.read_csv(\"winequality-train.csv\")\n",
    "test_df = pd.read_csv(\"winequality-test.csv\")\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distribution of labels \n",
    "def calc_prior(data):\n",
    "    prior_prob = {}\n",
    "\n",
    "    labels = data['quality']\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    n = counts.sum()\n",
    "\n",
    "    for i in range(len(unique_labels)):\n",
    "        prior_prob[unique_labels[i]] = (counts[i] / n).round(2)\n",
    "\n",
    "    return prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise training dataset split \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prior_probs = calc_prior(train_df)\n",
    "\n",
    "# Convert numerical keys to strings\n",
    "prior_probs_str = {str(key): value for key, value in prior_probs.items()}\n",
    "\n",
    "# Plotting\n",
    "plt.bar(prior_probs_str.keys(), prior_probs_str.values())\n",
    "plt.xlabel('Wine Quality')\n",
    "plt.ylabel('Prior Probability')\n",
    "plt.title('Distribution of Labels in Training Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and class for training df\n",
    "X_train = train_df.drop(columns=['quality'])\n",
    "y_train = train_df['quality']\n",
    "\n",
    "# Separate features and class for testing df\n",
    "X_test = test_df.drop(columns=['quality'])\n",
    "y_test = test_df['quality']\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "print(X_test.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the KNN classifier and fit it to the training data \n",
    "knn = KNNClassifier(k=5, debug=False)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = knn.predict(X_test.head(10))\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = np.mean(predictions == y_test.head(10))\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the predictions made by KNN Classifier\n",
    "num_instances = 10\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = knn.predict(X_test.head(num_instances))\n",
    "true_labels = y_test.head(num_instances)\n",
    "\n",
    "results_df = pd.DataFrame({'Predicted': predictions, 'True Label': true_labels})\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = round(np.mean(predictions == true_labels) * 100, 2)\n",
    "\n",
    "print(\"Results for the first\", num_instances, \"instances:\")\n",
    "print(results_df)\n",
    "print(f\"\\nOverall Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 1-NN classification\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer must be submitted separately as a PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for the first 50 instances:\n",
      "    Predicted  True Label\n",
      "0           0           0\n",
      "1           0           0\n",
      "2           1           1\n",
      "3           1           1\n",
      "4           1           1\n",
      "5           0           0\n",
      "6           1           0\n",
      "7           0           1\n",
      "8           0           0\n",
      "9           0           1\n",
      "10          0           0\n",
      "11          1           0\n",
      "12          0           0\n",
      "13          1           1\n",
      "14          0           0\n",
      "15          0           0\n",
      "16          0           0\n",
      "17          1           1\n",
      "18          1           0\n",
      "19          1           0\n",
      "20          0           0\n",
      "21          0           0\n",
      "22          0           0\n",
      "23          0           0\n",
      "24          0           0\n",
      "25          1           0\n",
      "26          0           0\n",
      "27          0           0\n",
      "28          0           0\n",
      "29          1           1\n",
      "30          0           0\n",
      "31          0           0\n",
      "32          0           0\n",
      "33          1           0\n",
      "34          0           1\n",
      "35          1           0\n",
      "36          1           1\n",
      "37          1           1\n",
      "38          0           0\n",
      "39          0           0\n",
      "40          0           0\n",
      "41          0           0\n",
      "42          0           0\n",
      "43          0           0\n",
      "44          0           0\n",
      "45          1           0\n",
      "46          0           0\n",
      "47          0           0\n",
      "48          1           0\n",
      "49          1           0\n",
      "\n",
      "Overall Accuracy: 74.0%\n"
     ]
    }
   ],
   "source": [
    "# Initiate 1-NN classifier and fit it to the training data \n",
    "knn = KNNClassifier(k=1, debug=False)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Visualise the predictions made by KNN Classifier\n",
    "num_instances = 50\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = knn.predict(X_test.head(num_instances))\n",
    "true_labels = y_test.head(num_instances)\n",
    "\n",
    "results_df = pd.DataFrame({'Predicted': predictions, 'True Label': true_labels})\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = round(np.mean(predictions == true_labels) * 100, 2)\n",
    "\n",
    "print(\"Results for the first\", num_instances, \"instances:\")\n",
    "print(results_df)\n",
    "print(f\"\\nOverall Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this dataset suitable for 1-NN classification? \n",
    "\n",
    "Attributes: fixedAcidity, volatileAcidity, citricAcid, residualSugar, chlorides, freeSulfurDioxide, totalSulfurDioxide, density, pH, sulphates, alcohol, quality\n",
    "\n",
    "Considerations for 1-NN Classifiers: The bias is low and variance is high. The probability of modelling the noise in the training data is high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D scatter plot of the 2 attributes above\n",
    "attribute1 = 'fixedAcidity'\n",
    "attribute2 = 'volatileAcidity'\n",
    "attribute3 = 'citricAcid'\n",
    "attribute4 = 'residualSugar'\n",
    "attribute5 = 'chlorides'\n",
    "attribute6 = 'freeSulfurDioxide'\n",
    "attribute7 = 'totalSulfurDioxide'\n",
    "attribute8 = 'density'\n",
    "attribute9 = 'pH'\n",
    "attribute10 = 'sulphates'\n",
    "attribute11 = 'alcohol'\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(train_df[train_df['quality'] == 0][attribute1], train_df[train_df['quality'] == 0][attribute2], c='blue', label='Low Quality - 0')\n",
    "plt.scatter(train_df[train_df['quality'] == 1][attribute1], train_df[train_df['quality'] == 1][attribute2], c='red', label='High Quality - 1')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(attribute1)\n",
    "plt.ylabel(attribute2)\n",
    "plt.title('Scatter Plot of Wine Quality')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalization\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer must be submitted separately as a PDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Min-max scale all attributes to the range 0 − 1: \n",
    "    $x′ = \\frac{x−min(x)}{max(x)−min(x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(train_df, test_df):\n",
    "    scaled_train_df = train_df.copy()\n",
    "    scaled_test_df = test_df.copy()\n",
    "\n",
    "    for col in train_df.columns:\n",
    "        min_val = train_df[col].min()\n",
    "        max_val = train_df[col].max()\n",
    "\n",
    "        scaled_train_df[col] = (train_df[col] - min_val) / (max_val - min_val)\n",
    "        scaled_test_df[col] = (test_df[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "    return scaled_train_df, scaled_test_df\n",
    "\n",
    "scaled_train_df, scaled_test_df = min_max_scaling(train_df, test_df)\n",
    "scaled_X_train = scaled_train_df.drop(columns=['quality'])\n",
    "scaled_X_test = scaled_test_df.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for the first 50 instances:\n",
      "    Predicted  True Label\n",
      "0           1           0\n",
      "1           0           0\n",
      "2           1           1\n",
      "3           1           1\n",
      "4           0           1\n",
      "5           0           0\n",
      "6           1           0\n",
      "7           1           1\n",
      "8           0           0\n",
      "9           0           1\n",
      "10          0           0\n",
      "11          0           0\n",
      "12          0           0\n",
      "13          1           1\n",
      "14          0           0\n",
      "15          0           0\n",
      "16          0           0\n",
      "17          1           1\n",
      "18          1           0\n",
      "19          1           0\n",
      "20          0           0\n",
      "21          0           0\n",
      "22          0           0\n",
      "23          1           0\n",
      "24          0           0\n",
      "25          0           0\n",
      "26          1           0\n",
      "27          0           0\n",
      "28          0           0\n",
      "29          1           1\n",
      "30          0           0\n",
      "31          0           0\n",
      "32          0           0\n",
      "33          0           0\n",
      "34          1           1\n",
      "35          0           0\n",
      "36          1           1\n",
      "37          1           1\n",
      "38          1           0\n",
      "39          0           0\n",
      "40          0           0\n",
      "41          0           0\n",
      "42          0           0\n",
      "43          0           0\n",
      "44          0           0\n",
      "45          1           0\n",
      "46          0           0\n",
      "47          0           0\n",
      "48          1           0\n",
      "49          0           0\n",
      "\n",
      "Overall Accuracy: 78.0%\n"
     ]
    }
   ],
   "source": [
    "# Initiate 1-NN classifier and fit it to the scaled training data \n",
    "knn = KNNClassifier(k=1, debug=False)\n",
    "knn.fit(scaled_X_train, y_train)\n",
    "\n",
    "# Visualise the predictions made by KNN Classifier\n",
    "num_instances = 50\n",
    "\n",
    "# Make predictions on the scaled test data\n",
    "predictions = knn.predict(scaled_X_test.head(num_instances))\n",
    "true_labels = y_test.head(num_instances)\n",
    "\n",
    "results_df = pd.DataFrame({'Predicted': predictions, 'True Label': true_labels})\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = round(np.mean(predictions == true_labels) * 100, 2)\n",
    "\n",
    "print(\"Results for the first\", num_instances, \"instances:\")\n",
    "print(results_df)\n",
    "print(f\"\\nOverall Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Standardize all attributes to have mean of 0 and standard deviation of 1\n",
    "    $x′ = \\frac{x−mean(x)}{stdev(x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train_df, test_df):\n",
    "    standardized_train_df = train_df.copy()\n",
    "    standardized_test_df = test_df.copy()\n",
    "\n",
    "    mean_vals = train_df.mean()\n",
    "    std_vals = train_df.std()\n",
    "\n",
    "    for col in train_df.columns:\n",
    "        standardized_train_df[col] = (train_df[col] - mean_vals[col]) / std_vals[col]\n",
    "        standardized_test_df[col] = (test_df[col] - mean_vals[col]) / std_vals[col]\n",
    "\n",
    "    return standardized_train_df, standardized_test_df\n",
    "\n",
    "standardized_train_df, standardized_test_df = standardize(train_df, test_df)\n",
    "standardized_X_train = standardized_train_df.drop(columns=['quality'])\n",
    "standardized_X_test = standardized_test_df.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for the first 50 instances:\n",
      "    Predicted  True Label\n",
      "0           0           0\n",
      "1           0           0\n",
      "2           1           1\n",
      "3           1           1\n",
      "4           1           1\n",
      "5           0           0\n",
      "6           1           0\n",
      "7           0           1\n",
      "8           0           0\n",
      "9           0           1\n",
      "10          0           0\n",
      "11          0           0\n",
      "12          0           0\n",
      "13          1           1\n",
      "14          0           0\n",
      "15          0           0\n",
      "16          0           0\n",
      "17          1           1\n",
      "18          1           0\n",
      "19          1           0\n",
      "20          0           0\n",
      "21          0           0\n",
      "22          0           0\n",
      "23          1           0\n",
      "24          0           0\n",
      "25          0           0\n",
      "26          1           0\n",
      "27          0           0\n",
      "28          0           0\n",
      "29          1           1\n",
      "30          0           0\n",
      "31          0           0\n",
      "32          0           0\n",
      "33          0           0\n",
      "34          1           1\n",
      "35          0           0\n",
      "36          1           1\n",
      "37          1           1\n",
      "38          1           0\n",
      "39          0           0\n",
      "40          0           0\n",
      "41          0           0\n",
      "42          0           0\n",
      "43          0           0\n",
      "44          0           0\n",
      "45          1           0\n",
      "46          0           0\n",
      "47          0           0\n",
      "48          1           0\n",
      "49          0           0\n",
      "\n",
      "Overall Accuracy: 80.0%\n"
     ]
    }
   ],
   "source": [
    "# Initiate 1-NN classifier and fit it to the standardized training data \n",
    "knn = KNNClassifier(k=1, debug=False)\n",
    "knn.fit(standardized_X_train, y_train)\n",
    "\n",
    "# Visualise the predictions made by KNN Classifier\n",
    "num_instances = 50\n",
    "\n",
    "# Make predictions on the standardized test data\n",
    "predictions = knn.predict(standardized_X_test.head(num_instances))\n",
    "true_labels = y_test.head(num_instances)\n",
    "\n",
    "results_df = pd.DataFrame({'Predicted': predictions, 'True Label': true_labels})\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = round(np.mean(predictions == true_labels) * 100, 2)\n",
    "\n",
    "print(\"Results for the first\", num_instances, \"instances:\")\n",
    "print(results_df)\n",
    "print(f\"\\nOverall Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model extensions\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer must be submitted separately as a PDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1\n",
    "\n",
    "Compare the performance of your best 1-NN model from Question 3 to a Gaussian naive Bayes model on this dataset (you may use library functions to implement the Gaussian naive Bayes model). In your write-up, state the accuracy of the naive Bayes model and identify instances where the two models disagree. Why do the two models classify these instances differently?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2\n",
    "\n",
    "Implement two additional distance measures for your K-NN model: cosine similarity and Mahalanobis distance (you may use library functions for these distance measures). Do 1-NN classification using each of these new distance measures and the three normalization options from Question 3. Discuss how the new distance metrics compare to Euclidean distance and how each metric is affected by normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3\n",
    "\n",
    "Implement either of the two K-NN weighting strategies discussed in lecture (inverse linear distance or inverse distance). Compare the performance of the weighted and majority vote models for a few different values of K. In your write-up, discuss how weighting strategy and the value of K affect the model's decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4\n",
    "\n",
    "Measure the empirical distribution of class labels in the training dataset (what percentage of the training data comes from each class). Then evaluate the distribution of labels predicted by your K-NN model for the test data, for a range of values for K. Does the class distribution of the predicted labels match the class distribution of the training data? Explain why or why not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
